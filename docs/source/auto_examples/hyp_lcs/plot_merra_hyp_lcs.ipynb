{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n# MERRA-2 Hyperbolic LCS\n\nCompute hyperbolic LCS using the variational theory for atmospheric flow at time of Godzilla dust\nstorm using MERRA-2 data which is vertically averaged over pressure surfaces\nranging from 500hPa to 800hPa..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Author: ajarvis\n",
    "# Data: MERRA-2 - Global Modeling and Assimilation Office - NASA\n",
    "\n",
    "import numpy as np\n",
    "from math import copysign\n",
    "from numbacs.flows import get_interp_arrays_2D, get_flow_2D\n",
    "from numbacs.integration import flowmap_aux_grid_2D\n",
    "from numbacs.diagnostics import C_eig_aux_2D, ftle_from_eig\n",
    "from numbacs.extraction import hyperbolic_lcs\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get flow data\nLoad in atmospheric velocity data, dates, and coordinates. Set domain for \nFTLE computation and integration span. Create interpolant and retrieve flow.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>Pandas is a simpler option for storing and manipulating dates but we use\n   numpy here as Pandas is not a dependency.</p></div>\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load in atmospheric data\n",
    "dates = np.load('../data/merra_june2020/dates.npy')\n",
    "dt = (dates[1] - dates[0]).astype('timedelta64[h]').astype(int)\n",
    "t = np.arange(0,len(dates)*dt,dt,np.float64)\n",
    "lon = np.load('../data/merra_june2020/lon.npy')\n",
    "lat = np.load('../data/merra_june2020/lat.npy')\n",
    "\n",
    "# NumbaCS uses 'ij' indexing, most geophysical data uses 'xy'\n",
    "# indexing for the spatial coordintes. We need to switch axes and\n",
    "# scale by 3.6 since velocity data is in m/s and we want km/hr.\n",
    "u = np.moveaxis(np.load('../data/merra_june2020/u_500_800hPa.npy'),1,2)*3.6\n",
    "v = np.moveaxis(np.load('../data/merra_june2020/v_500_800hPa.npy'),1,2)*3.6\n",
    "nt,nx,ny = u.shape\n",
    "\n",
    "# set domain on which ftle will be computed\n",
    "dx = 0.1\n",
    "dy = 0.1\n",
    "lonf = np.arange(-100,35+dx,dx)\n",
    "latf = np.arange(-5,45+dy,dy)\n",
    "\n",
    "\n",
    "# set integration span and integration direction\n",
    "day = 16\n",
    "t0_date = np.datetime64(\"2020-06-{:02d}\".format(day))\n",
    "t0 = t[np.nonzero(dates == t0_date)[0][0]]\n",
    "T = -72.0\n",
    "params = np.array([copysign(1,T)])\n",
    "\n",
    "# get interpolant arrays of velocity field\n",
    "grid_vel, C_eval_u, C_eval_v = get_interp_arrays_2D(t, lon, lat, u, v)\n",
    "\n",
    "# set integration direction and retrieve flow\n",
    "# set spherical = 1 since flow is on spherical domain and lon is from [-180,180)\n",
    "params = np.array([copysign(1,T)])\n",
    "funcptr = get_flow_2D(grid_vel, C_eval_u, C_eval_v, spherical=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrate\nIntegrate grid of particles and auxillary grid with spacing h, return final positions\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# computes final position of particle trajectories over grid + auxillary grid\n",
    "# with spacing h\n",
    "h = 5e-3\n",
    "flowmap = flowmap_aux_grid_2D(funcptr, t0, T, lonf, latf, params,h=h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CG eigenvalues, eigenvectors, and FTLE\nCompute eigenvalues/vectors of CG tensor from final particle positions and compute FTLE.\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute eigenvalues/vectors of Cauchy Green tensor\n",
    "eigvals,eigvecs = C_eig_aux_2D(flowmap, dx, dy, h=h)\n",
    "eigval_max = eigvals[:,:,1]\n",
    "eigvec_max = eigvecs[:,:,:,1]\n",
    "\n",
    "# copmute FTLE from max eigenvalue\n",
    "ftle = ftle_from_eig(eigval_max,T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperbolic LCS\nCompute hyperbolic LCS using the variational theory.\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set parameters for hyperbolic lcs extraction,\n",
    "# see function description for more details\n",
    "step_size = 5e-3\n",
    "steps = 10000\n",
    "lf = 0.15\n",
    "lmin = 5.0\n",
    "r = 2.0\n",
    "nmax = 2000\n",
    "dtol = 0\n",
    "nlines = 20\n",
    "percentile=0\n",
    "ep_dist_tol=0.0\n",
    "lambda_avg_min = 0\n",
    "arclen_flag=False\n",
    "\n",
    "# extract hyperbolic lcs\n",
    "lcs = hyperbolic_lcs(eigval_max, eigvecs, lonf, latf, step_size, steps, lf, lmin, r, nmax,\n",
    "                     dist_tol=dtol,\n",
    "                     nlines=nlines,\n",
    "                     ep_dist_tol=ep_dist_tol,\n",
    "                     percentile=percentile,\n",
    "                     lambda_avg_min=lambda_avg_min,\n",
    "                     arclen_flag=arclen_flag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot\nPlot the results.\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coastlines = np.load('../data/merra_june2020/coastlines.npy')\n",
    "fig,ax = plt.subplots(dpi=200)\n",
    "ax.scatter(coastlines[:,0],coastlines[:,1],1,'k',marker='.',edgecolors=None,linewidths=0)\n",
    "ax.contourf(lonf,latf,ftle.T,levels=80,zorder=0)\n",
    "for l in lcs:\n",
    "    ax.plot(l[:,0],l[:,1],'r',lw=0.5)\n",
    "\n",
    "ax.set_xlim([lonf[0],lonf[-1]])\n",
    "ax.set_ylim([latf[0],latf[-1]])\n",
    "ax.set_aspect('equal')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
